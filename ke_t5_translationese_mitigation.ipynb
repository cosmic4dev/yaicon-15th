{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b2b9af-75d6-40f1-9479-9f5dea4a3dc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19555df4-bd98-4bf0-9cac-e16504370f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.40.2\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.40.2)\n",
      "  Downloading huggingface_hub-0.32.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.40.2)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.2)\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.40.2)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2)\n",
      "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.2) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.2) (2024.7.4)\n",
      "Using cached transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "Downloading huggingface_hub-0.32.1-py3-none-any.whl (509 kB)\n",
      "Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Installing collected packages: safetensors, regex, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.1.2 huggingface-hub-0.32.1 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.19.1 transformers-4.40.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.32.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: hf_xet in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.32.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/13\u001b[0m [datasets]/13\u001b[0m [datasets]ess]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.2 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.6.0 dill-0.3.8 frozenlist-1.6.0 multidict-6.4.4 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 xxhash-3.5.0 yarl-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.3.1+cu121)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.40.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.24.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.32.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=3.0.0->bert-score) (1.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->bert-score) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting blobfile\n",
      "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pycryptodomex>=3.8 (from blobfile)\n",
      "  Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile) (2.2.2)\n",
      "Collecting lxml>=4.9 (from blobfile)\n",
      "  Downloading lxml-5.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile) (3.13.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pycryptodomex, lxml, tiktoken, blobfile\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [blobfile]3/4\u001b[0m [blobfile]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blobfile-3.0.0 lxml-5.4.0 pycryptodomex-3.23.0 tiktoken-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets==3.6.0 in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (0.32.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==3.6.0) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.7)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.6.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.6.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting huggingface_hub==0.32.0\n",
      "  Downloading huggingface_hub-0.32.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.32.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.32.0) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.32.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.32.0) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.32.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.32.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.32.0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.32.0) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.32.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.32.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.32.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.32.0) (2024.7.4)\n",
      "Downloading huggingface_hub-0.32.0-py3-none-any.whl (509 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.32.1\n",
      "    Uninstalling huggingface-hub-0.32.1:\n",
      "      Successfully uninstalled huggingface-hub-0.32.1\n",
      "Successfully installed huggingface_hub-0.32.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.40.2\n",
    "!pip install accelerate\n",
    "!pip install hf_xet\n",
    "!pip install datasets\n",
    "!pip install bert-score\n",
    "!pip install blobfile tiktoken\n",
    "!pip install torch\n",
    "!pip install datasets==3.6.0\n",
    "!pip install huggingface_hub==0.32.0\n",
    "!pip install sentencepiece\n",
    "#!pip install transformers==4.35.2 tokenizers==0.14.1 huggingface_hub==0.16.4 accelerate==0.26.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d90fb3-9889-4280-af2c-6793f05c9e64",
   "metadata": {},
   "source": [
    "## Load the Model & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83dce109-3201-4856-a7a8-446710c70c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"KETI-AIR/ke-t5-base-ko\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"KETI-AIR/ke-t5-base-ko\", \n",
    "    use_fast=False, \n",
    "    trust_remote_code=True,\n",
    "    legacy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1762b3cd-9eb2-42d9-bfaf-6e86a35ac9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094a770061064c58bc894c9ec4f4a4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=\"Data_filtered.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    split={\n",
    "        \"train\": \"train[:80%]\",\n",
    "        \"validation\": \"train[80%:90%]\",\n",
    "        \"test\": \"train[90%:]\"\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset = dataset.filter(lambda x: x[\"ko_translationese\"] is not None and x[\"ko\"] is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd92b4-6502-497a-ace6-5392a8831ee9",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a944038-dc03-41ed-9fef-ef6e8b7e8fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f079a89a934ded9680d194bf922ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(example):\n",
    "    # 프롬프트 형태를 명시적으로 포함\n",
    "    input_text = \"번역투 완화: \" + example[\"ko_translationese\"]\n",
    "    target_text = example[\"ko\"]\n",
    "\n",
    "    model_inputs = tokenizer(input_text, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(target_text, max_length=128, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675df83f-eb0f-42d8-80df-a15f2d16c8eb",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49242248-112a-486b-b07e-5cf154622940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100 \n",
    ")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./ke-t5-translationese-mitigation\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,\n",
    "    logging_steps=1000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a2b2f82-d01b-4a68-b988-d695e12a4a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52775' max='63535' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52775/63535 6:37:33 < 1:21:03, 2.21 it/s, Epoch 4.15/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>155.316800</td>\n",
       "      <td>95.147331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>87.125400</td>\n",
       "      <td>34.044762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>10.687900</td>\n",
       "      <td>1.628902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.615800</td>\n",
       "      <td>1.438149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.391600</td>\n",
       "      <td>1.082923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.060800</td>\n",
       "      <td>0.706245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.796300</td>\n",
       "      <td>0.567908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.674000</td>\n",
       "      <td>0.521763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.609700</td>\n",
       "      <td>0.490314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.471900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.550400</td>\n",
       "      <td>0.458310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.527900</td>\n",
       "      <td>0.449932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.510300</td>\n",
       "      <td>0.436880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.427605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.480900</td>\n",
       "      <td>0.425339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.480100</td>\n",
       "      <td>0.416655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.471400</td>\n",
       "      <td>0.413536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.408319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.403151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.399244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.451300</td>\n",
       "      <td>0.396090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.394395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.390802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.436700</td>\n",
       "      <td>0.387185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.432500</td>\n",
       "      <td>0.384628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.384481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.424200</td>\n",
       "      <td>0.380484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.379224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.419500</td>\n",
       "      <td>0.378346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.418800</td>\n",
       "      <td>0.374783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.370606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.372933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.410600</td>\n",
       "      <td>0.371782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>0.369101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.367046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.410300</td>\n",
       "      <td>0.365229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.403600</td>\n",
       "      <td>0.366538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.365683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.361580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.399600</td>\n",
       "      <td>0.363088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.362660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>0.360923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.399800</td>\n",
       "      <td>0.360173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.358343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.358036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.393600</td>\n",
       "      <td>0.357827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>0.356524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.355927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.355422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.355025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.389000</td>\n",
       "      <td>0.355433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>0.354720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "5d65b9ac-52e4-4a8b-ace6-4ca2ce2f9491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.190344</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.236802</td>\n",
       "      <td>62.7818</td>\n",
       "      <td>170.416</td>\n",
       "      <td>10.656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2402</td>\n",
       "      <td>0.244009</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.236675</td>\n",
       "      <td>62.6919</td>\n",
       "      <td>170.660</td>\n",
       "      <td>10.671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2411</td>\n",
       "      <td>0.224249</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.560748</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  grad_norm  learning_rate     epoch  step  eval_loss  eval_runtime  \\\n",
       "0  0.2545   0.190344       0.000047  0.186916  1000        NaN           NaN   \n",
       "1     NaN        NaN            NaN  0.186916  1000   0.236802       62.7818   \n",
       "2  0.2402   0.244009       0.000045  0.373832  2000        NaN           NaN   \n",
       "3     NaN        NaN            NaN  0.373832  2000   0.236675       62.6919   \n",
       "4  0.2411   0.224249       0.000040  0.560748  3000        NaN           NaN   \n",
       "\n",
       "   eval_samples_per_second  eval_steps_per_second  train_runtime  \\\n",
       "0                      NaN                    NaN            NaN   \n",
       "1                  170.416                 10.656            NaN   \n",
       "2                      NaN                    NaN            NaN   \n",
       "3                  170.660                 10.671            NaN   \n",
       "4                      NaN                    NaN            NaN   \n",
       "\n",
       "   train_samples_per_second  train_steps_per_second  total_flos  train_loss  \n",
       "0                       NaN                     NaN         NaN         NaN  \n",
       "1                       NaN                     NaN         NaN         NaN  \n",
       "2                       NaN                     NaN         NaN         NaN  \n",
       "3                       NaN                     NaN         NaN         NaN  \n",
       "4                       NaN                     NaN         NaN         NaN  "
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "log_history = trainer.state.log_history\n",
    "log_df = pd.DataFrame(log_history)\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b5a6b-0576-458b-911f-96659afd920c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# step ≥ 10000 이후 데이터만 필터링\n",
    "train_loss = log_df[(log_df[\"loss\"].notnull()) & (log_df[\"step\"] >= 10000)]\n",
    "eval_loss = log_df[(log_df[\"eval_loss\"].notnull()) & (log_df[\"step\"] >= 10000)]\n",
    "\n",
    "# 스텝 기준 선 그래프\n",
    "plt.plot(train_loss[\"step\"], train_loss[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(eval_loss[\"step\"], eval_loss[\"eval_loss\"], label=\"Eval Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Evaluation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "2ad9340a-fb1d-4e87-92ff-8bb69a4826c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: ko_translationese, ko, similarity, en. If ko_translationese, ko, similarity, en are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10699\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='669' max='669' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [669/669 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2299094945192337, 'eval_runtime': 62.7029, 'eval_samples_per_second': 170.63, 'eval_steps_per_second': 10.669, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "final_metrics = trainer.evaluate()\n",
    "print(final_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e6c3b-64ef-47d4-a73e-652476b61e03",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5748481-1635-4465-bffe-3a57a44646d5",
   "metadata": {},
   "source": [
    "#### KoBERT score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "1ca1b72d-1e4e-42d8-8c43-765baf046b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/38279184ba645e8c94d709fbe92eb5bcb47312c1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"monologg/kobert\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8002\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/38279184ba645e8c94d709fbe92eb5bcb47312c1/model.safetensors\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at monologg/kobert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file tokenizer_78b3253a26.model from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/38279184ba645e8c94d709fbe92eb5bcb47312c1/tokenizer_78b3253a26.model\n",
      "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/38279184ba645e8c94d709fbe92eb5bcb47312c1/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/38279184ba645e8c94d709fbe92eb5bcb47312c1/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "similarity_model = AutoModel.from_pretrained(\"monologg/kobert\")\n",
    "similarity_tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "similarity_model = similarity_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "426cc573-07d3-4891-972a-da950cef7a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_batch(texts1, texts2, batch_size=8):\n",
    "    results = []\n",
    "    for i in range(0, len(texts1), batch_size):\n",
    "        batch1 = texts1[i:i+batch_size]\n",
    "        batch2 = texts2[i:i+batch_size]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tokens1 = similarity_tokenizer(batch1, return_tensors=\"pt\", truncation=True, padding=True, max_length=None).to(device)\n",
    "            tokens2 = similarity_tokenizer(batch2, return_tensors=\"pt\", truncation=True, padding=True, max_length=None).to(device)\n",
    "\n",
    "            emb1 = similarity_model(**tokens1).last_hidden_state.mean(dim=1)\n",
    "            emb2 = similarity_model(**tokens2).last_hidden_state.mean(dim=1)\n",
    "\n",
    "            batch_scores = F.cosine_similarity(emb1, emb2)\n",
    "            batch_scores = torch.clamp(batch_scores, max=1.0)\n",
    "            results.extend(batch_scores.cpu().numpy().tolist())\n",
    "    return results\n",
    "    \n",
    "def compute_metrics_kobert(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    if preds.ndim == 3:\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    def remove_padding(token_ids):\n",
    "        return [token for token in token_ids if token != -100]\n",
    "\n",
    "    preds = [remove_padding(p) for p in preds]\n",
    "    labels = [remove_padding(l) for l in labels]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    try:\n",
    "        scores = get_similarity_batch(decoded_preds, decoded_labels)\n",
    "    except Exception as e:\n",
    "        print(f\"Similarity error: {e}\")\n",
    "        scores = [0.0] * len(decoded_preds)\n",
    "\n",
    "    return {\n",
    "        \"avg_similarity\": float(np.mean(scores)),\n",
    "        \"max_similarity\": float(np.max(scores)),\n",
    "        \"min_similarity\": float(np.min(scores)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "97accb63-21cb-4791-9601-461bbc104c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_sampled = tokenized_dataset[\"test\"].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e3f0e-1f0a-453d-b27f-f05150f9a4bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100 \n",
    ")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./ke-t5-translationese-mitigation\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,\n",
    "    logging_steps=1000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=test_dataset_sampled,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_kobert\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "bae893a4-d96a-4289-aa47-9ba9afd65a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: ko_translationese, ko, similarity, en. If ko_translationese, ko, similarity, en are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10699\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='1338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  17/1338 00:01 < 01:50, 11.90 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.65 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[482], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ko vs. mitigated \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_seq2seq.py:180\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3467\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3464\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3466\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3467\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3468\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3477\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3670\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3668\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n\u001b[1;32m   3669\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((logits))\n\u001b[0;32m-> 3670\u001b[0m     \u001b[43mall_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3672\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py:326\u001b[0m, in \u001b[0;36mEvalLoopContainer.add\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat \u001b[38;5;28;01melse\u001b[39;00m [tensors]\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mappend(tensors)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py:138\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\n\u001b[1;32m    135\u001b[0m     new_tensors\n\u001b[1;32m    136\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py:138\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\n\u001b[1;32m    135\u001b[0m     new_tensors\n\u001b[1;32m    136\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py:140\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[1;32m    143\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    144\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py:99\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     96\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[1;32m    102\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.65 GiB. GPU "
     ]
    }
   ],
   "source": [
    "# ko vs. mitigated \n",
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6a2b4-75b9-4dae-ba34-6b4bafd12a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_sample = dataset[\"test\"].shuffle(seed=1023).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "16ddbc37-18f2-4d84-bec0-17f99b477e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:22<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ko_translationese 입력 문장\n",
    "source_texts = test_dataset_sample[\"ko_translationese\"]\n",
    "reference_texts = test_dataset_sample[\"ko\"]\n",
    "\n",
    "# 생성 결과 저장용\n",
    "mitigated_texts = []\n",
    "\n",
    "model.eval()\n",
    "for i in tqdm(range(0, len(source_texts), 4)):  # 소량 batch로 쪼개서 메모리 절약\n",
    "    batch = source_texts[i:i+4]\n",
    "    inputs = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.9,\n",
    "            top_p=0.4,\n",
    "            repetition_penalty=1.2,\n",
    "            do_sample=True,\n",
    "            no_repeat_ngram_size=3,\n",
    "            decoder_start_token_id = model.config.decoder_start_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    mitigated_texts.extend(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0390c-04e4-4069-9504-0bc27eb4746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoBERT avg similarity: 0.8123\n",
      "KoBERT max similarity: 0.9786\n",
      "KoBERT min similarity: 0.4497\n"
     ]
    }
   ],
   "source": [
    "# ko vs. mitigated\n",
    "similarities = get_similarity_batch(reference_texts, mitigated_texts)\n",
    "\n",
    "print(f\"KoBERT avg similarity: {np.mean(similarities):.4f}\")\n",
    "print(f\"KoBERT max similarity: {np.max(similarities):.4f}\")\n",
    "print(f\"KoBERT min similarity: {np.min(similarities):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "4e2df7fa-6a48-4bd9-b6da-9d4c8e7405df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoBERT avg similarity: 0.8696\n",
      "KoBERT max similarity: 1.0000\n",
      "KoBERT min similarity: 0.5580\n"
     ]
    }
   ],
   "source": [
    "# ko vs. translated_ko\n",
    "similarities = get_similarity_batch(test_dataset_sample['ko'], test_dataset_sample['ko_translationese'])\n",
    "\n",
    "print(f\"KoBERT avg similarity: {np.mean(similarities):.4f}\")\n",
    "print(f\"KoBERT max similarity: {np.max(similarities):.4f}\")\n",
    "print(f\"KoBERT min similarity: {np.min(similarities):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe0ecc-7c04-4b6f-a81f-7ae91b696024",
   "metadata": {},
   "source": [
    "#### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "a9ad6caa-9014-457b-a1c4-c812dc11075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.26\n"
     ]
    }
   ],
   "source": [
    "# ko vs. mitigated\n",
    "import math\n",
    "if \"eval_loss\" in eval_results:\n",
    "    ppl = math.exp(eval_results[\"eval_loss\"])\n",
    "    print(f\"Perplexity: {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f806a16-c4ab-4a3f-a021-7fde2e8d641d",
   "metadata": {},
   "source": [
    "### MATTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "f4a70e6c-7ba6-442a-879c-7cb19a7d6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_texts = [s for s in mitigated_texts if len(s.strip().split()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0ad523db-b2c3-48ca-8a81-633f908d44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# window size로 ttr 계산 범위 조정  \n",
    "def mattr(text, window_size=50):\n",
    "    tokens = text.split()\n",
    "    if len(tokens) < window_size:\n",
    "        return len(set(tokens)) / len(tokens)\n",
    "    \n",
    "    ttr_list = []\n",
    "    for i in range(len(tokens) - window_size + 1):\n",
    "        window = tokens[i:i + window_size]\n",
    "        ttr_list.append(len(set(window)) / window_size)\n",
    "    \n",
    "    return sum(ttr_list) / len(ttr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df143fe-3a33-4e4d-b103-0ccaf2075328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MATTR of Original Texts: 0.9961\n"
     ]
    }
   ],
   "source": [
    "original_texts = dataset['test']['ko']\n",
    "total_mattr_original = 0\n",
    "for sent in original_texts:\n",
    "    total_mattr_original += mattr(sent, window_size=50)\n",
    "\n",
    "average_mattr_original = total_mattr_original / len(original_texts)\n",
    "print(f\"Average MATTR of Original Texts: {average_mattr_original:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d127d-2360-4ed2-9a86-8ecb7c0860c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MATTR of Translationese Texts: 0.9941\n"
     ]
    }
   ],
   "source": [
    "translationese_texts = dataset['test']['ko_translationese']\n",
    "total_mattr_translationese = 0\n",
    "\n",
    "for sent in translationese_texts:\n",
    "    total_mattr_translationese += mattr(sent, window_size=50)\n",
    "\n",
    "average_mattr_translationese = total_mattr_translationese / len(translationese_texts)\n",
    "print(f\"Average MATTR of Translationese Texts: {average_mattr_translationese:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "b194ac8b-3d60-4180-aa6a-48f0c2015b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MATTR of Mitigated Texts: 0.9977\n"
     ]
    }
   ],
   "source": [
    "total_mattr_mitigated = 0\n",
    "for sent in generated_texts:\n",
    "    total_mattr_mitigated += mattr(sent, window_size=50)\n",
    "\n",
    "average_mattr_mitigated = total_mattr_mitigated / len(generated_texts)\n",
    "print(f\"Average MATTR of Mitigated Texts: {average_mattr_mitigated:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
